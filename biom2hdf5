#!/usr/bin/env python
from __future__ import division

__author__ = "Jai Ram Rideout"
__copyright__ = "Copyright 2013, BIOM-Format Project"
__credits__ = ["Jai Ram Rideout"]
__license__ = "GPL"
__url__ = "http://biom-format.org"
__version__ = "1.2.0-dev"
__maintainer__ = "Jai Ram Rideout"
__email__ = "jai.rideout@gmail.com"

import sys
import h5py
import numpy

def parse_field(table_str, field, required=True):
    search_str = '"%s": "' % field

    try:
        start_idx = table_str.index(search_str) + len(search_str)
    except ValueError:
        if required:
            raise ValueError("Missing required field '%s'." % field)
        else:
            return None
    else:
        end_idx = table_str.index('",', start_idx)
        return table_str[start_idx:end_idx]

def parse_shape(table_str):
    search_str = '"shape": ['
    start_idx = table_str.index(search_str) + len(search_str)
    end_idx = table_str.index('],', start_idx)
    dim_strs = table_str[start_idx:end_idx].split(', ')
    assert len(dim_strs) == 2
    return tuple(map(int, dim_strs))

def parse_data(table_str):
    search_str = '"data": [['
    start_idx = table_str.index(search_str) + len(search_str)

    while True:
        end_idx = table_str.index(']', start_idx)
        data_strs = table_str[start_idx:end_idx].split(',')
        #assert len(data_strs) == 3
        yield int(data_strs[0]), int(data_strs[1]), float(data_strs[2])

        if table_str[end_idx + 1] == ',':
            start_idx = end_idx + 3
        else:
            break

def parse_metadata(table_str, axis):
    search_str = '"%s": [{' % axis
    start_idx = table_str.index(search_str) + len(search_str)

    while True:
        end_idx = table_str.index('}', start_idx)
        fields = table_str[start_idx:end_idx].split(', ')
        assert len(fields) == 2
        yield fields[0].split('"id": "')[1][:-1]

        if table_str[end_idx + 1] == ',':
            start_idx = end_idx + 3
        else:
            break

in_fp, out_fp, mode = sys.argv[1:]
in_f = open(in_fp, 'U')
table_str = in_f.read()
in_f.close()

table_id = parse_field(table_str, 'id')
version = parse_field(table_str, 'format')
url = parse_field(table_str, 'format_url')
table_type = parse_field(table_str, 'type')
generated_by = parse_field(table_str, 'generated_by')
date = parse_field(table_str, 'date')
matrix_type = parse_field(table_str, 'matrix_type')
matrix_element_type = parse_field(table_str, 'matrix_element_type')
comment = parse_field(table_str, 'comment', required=False)
shape = parse_shape(table_str)
data = parse_data(table_str)
obs_ids = list(parse_metadata(table_str, 'rows'))
sample_ids = list(parse_metadata(table_str, 'columns'))

print table_id
print version
print url
print table_type
print generated_by
print date
print matrix_type
print matrix_element_type
print comment
print shape

print "Creating HDF5 file...",
out_f = h5py.File(out_fp, 'w')
print "Done"

print "Populating top-level metadata fields...",
out_f.attrs['id'] = table_id
out_f.attrs['format'] = version
out_f.attrs['format_url'] = url
out_f.attrs['type'] = table_type
out_f.attrs['generated_by'] = generated_by
out_f.attrs['date'] = date
out_f.attrs['matrix_type'] = matrix_type
out_f.attrs['matrix_element_type'] = matrix_element_type
if comment is not None:
    out_f.attrs['comment'] = comment
out_f.attrs['shape'] = shape
print "Done"

if mode == 'dense':
    print "Creating dataset...",
    dset = out_f.create_dataset('data', shape, dtype=matrix_element_type,
                                compression='gzip')
    print "Done"

    print "Writing data...",
    count = 0
    for e in data:
        dset[e[0], e[1]] = e[2]
        count += 1

        if (count % 100000) == 0:
            print "Flushing, NNZ processed: %d..." % count,
            out_f.flush()
            print "Done"
    out_f.flush()
    print "Done"

    print "Populating metadata...",
    out_f['rows'] = obs_ids
    out_f['columns'] = sample_ids
    dset.dims[0].label = 'observations'
    dset.dims[1].label = 'samples'
    dset.dims.create_scale(out_f['rows'], 'ids')
    dset.dims.create_scale(out_f['columns'], 'ids')
    dset.dims[0].attach_scale(out_f['rows'])
    dset.dims[1].attach_scale(out_f['columns'])
    print "Done"
elif mode == 'sparse':
    print "Populating metadata...",
    out_f['rows'] = obs_ids
    out_f['columns'] = sample_ids
    out_f.flush()
    del obs_ids
    del sample_ids
    print "Done"

    print "Counting number of nonzero entries...",
    nnz = 0
    for e in data:
        nnz += 1
    print "Done"
    print "NNZ: %d" % nnz
    print "Table density: %r" % (nnz / (shape[0] * shape[1]))
    data = parse_data(table_str)

    #nnz = 107439386

    print "Loading data into memory...",
    count = 0
    nonzeros = numpy.empty((nnz, 3))
    for e in data:
        nonzeros[count] = e
        count += 1

        if (count % 100000) == 0:
            print '%.2f%%' % ((count / nnz) * 100)
    print "Done"

    print "Creating dataset...",
    dset = out_f.create_dataset('data', data=nonzeros)
    out_f.flush()
    print "Done"
else:
    raise ValueError

out_f.close()
